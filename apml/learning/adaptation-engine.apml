# Adaptation Engine Specification
# SSi Learning App
#
# Version: 1.3.0
# Date: 2025-12-16
# Grounded in: Distinction as Primitive (APML Design Principles v2.0.0)
#
# Core Insight: We don't measure absolutes. We measure DIFFERENCES.
# A "slow" response is one that differs from THIS learner's pattern.
# Everything is a parameter. We're looking for discontinuities.
#
# NEW in v1.3.0: HIERARCHICAL ADAPTATION
# - Level 1 (Global): Learner Tempo Profile - what kind of learner overall?
# - Level 2 (Local): Differential detection - how is this moment different?
#
# Implementation Status:
# - MasteryStateMachine: INTEGRATED
# - WeightedSelector: INTEGRATED
# - VoiceActivityDetector: implemented, ready for integration
# - LearnerTempoProfile: SPECIFIED, ready for implementation

spec AdaptationEngine:
  version: "1.3.0"
  philosophical_grounding: |
    Distinctions cost energy. Observers have finite budgets.
    Therefore: we detect DIFFERENCES, not absolutes.

    A response is "slow" not because it exceeds some universal threshold,
    but because it differs from the learner's own rolling pattern.

    This is self-calibrating, personal, and thermodynamically efficient.

  # ===========================================================================
  # MEASUREMENT PRIMITIVES
  # ===========================================================================

  measurements:
    description: "Raw signals captured per response cycle"

    latency:
      what: "Time from PAUSE start to learner vocalization end"
      unit: milliseconds
      capture: "End of PAUSE phase (or speech detection if available)"
      fallback: "PAUSE duration if no speech detection"

    response_length:
      what: "Duration of learner's spoken response"
      unit: milliseconds
      capture: "Speech detection start to end"
      fallback: "null if no speech detection"
      note: "Initially may not be available - that's fine"

    model_length:
      what: "Duration of target audio (what learner is trying to produce)"
      unit: milliseconds
      source: "audio_samples.duration_ms"

  # ===========================================================================
  # DIFFERENTIAL CALCULATIONS (Core of adaptation)
  # ===========================================================================

  differentials:
    description: |
      We don't compare to absolute thresholds.
      We compare to the learner's own rolling pattern.
      Discontinuities = valuable signal.

    latency_differential:
      formula: "current_latency - rolling_average(latency, window_size)"
      parameters:
        window_size:
          default: 7
          range: [3, 15]
          description: "Number of previous responses to average"

      interpretation:
        positive: "Slower than usual - possible struggle"
        negative: "Faster than usual - confident or rushed"
        near_zero: "Consistent with pattern - normal"

    length_delta:
      formula: "response_length - model_length"
      description: "How much longer/shorter learner spoke than target"

      interpretation:
        positive: "Learner spoke longer - hesitation, self-correction, or elaboration"
        negative: "Learner spoke shorter - truncated, uncertain, or efficient"
        near_zero: "Matched model - confident reproduction"

    length_delta_differential:
      formula: "current_length_delta - rolling_average(length_delta, window_size)"
      parameters:
        window_size:
          default: 7
          range: [3, 15]

      interpretation:
        positive: "Speaking longer than their usual delta - new hesitation"
        negative: "Speaking shorter than their usual delta - new confidence or giving up"
        near_zero: "Consistent pattern"

  # ===========================================================================
  # DISCONTINUITY DETECTION
  # ===========================================================================

  discontinuity_detection:
    description: |
      A discontinuity is when the current differential exceeds
      a threshold relative to the learner's own variance.

      We use standard deviations from rolling stats, not absolute values.
      This makes detection personal and self-calibrating.

    latency_discontinuity:
      formula: |
        discontinuity = abs(latency_differential) > (stddev_threshold * rolling_stddev(latency, window_size))

      parameters:
        stddev_threshold:
          default: 2.0
          range: [1.5, 3.0]
          description: "Number of standard deviations to trigger discontinuity"
        window_size:
          default: 7
          range: [3, 15]

      signal:
        detected: "Learner's latency pattern has broken - something changed"
        direction: "sign(latency_differential)"
        magnitude: "abs(latency_differential) / rolling_stddev"

    length_discontinuity:
      formula: |
        discontinuity = abs(length_delta_differential) > (stddev_threshold * rolling_stddev(length_delta, window_size))

      parameters:
        stddev_threshold:
          default: 2.0
          range: [1.5, 3.0]
        window_size:
          default: 7
          range: [3, 15]

      signal:
        detected: "Learner's response length pattern has broken"
        direction: "sign(length_delta_differential)"
        magnitude: "abs(length_delta_differential) / rolling_stddev"

    combined_discontinuity:
      description: "Either or both signals can indicate a pattern break"
      formula: "latency_discontinuity OR length_discontinuity"

      severity:
        mild: "One discontinuity, magnitude < 2.5σ"
        moderate: "One discontinuity, magnitude >= 2.5σ, OR both discontinuities"
        severe: "Both discontinuities, combined magnitude > 4σ"

  # ===========================================================================
  # RESPONSE TO DISCONTINUITIES
  # ===========================================================================

  adaptation_responses:
    description: |
      When we detect a discontinuity, we adjust parameters.
      The adjustments themselves are parameterized.
      We're not making hard decisions - we're nudging gradients.

    on_latency_spike:
      description: "Learner took longer than their pattern"

      immediate_response:
        extend_pause:
          enabled: true
          formula: "pause_duration * (1 + extension_factor)"
          parameters:
            extension_factor:
              default: 0.3
              range: [0.1, 0.5]
              description: "How much to extend pause on next occurrence"

      lego_state_response:
        description: "Affects mastery progression"
        action: "hold_position"
        rationale: "Don't advance - learner hasn't consolidated"

      selection_weight_response:
        description: "Affects future selection probability"
        formula: "weight * boost_factor"
        parameters:
          boost_factor:
            default: 2.0
            range: [1.5, 5.0]
            description: "Increase likelihood of practicing this LEGO again soon"

    on_latency_fast:
      description: "Learner responded faster than their pattern"

      interpretation: "Could be confidence OR rushing/guessing"

      immediate_response:
        none: "Don't change pause - might be genuine confidence"

      lego_state_response:
        action: "advance_if_consistent"
        condition: "fast_responses >= consistency_threshold"
        parameters:
          consistency_threshold:
            default: 3
            range: [2, 5]
            description: "Consecutive fast responses before advancing"

    on_length_spike:
      description: "Learner spoke longer than their pattern (hesitation, self-correction)"

      immediate_response:
        extend_pause:
          enabled: true
          formula: "pause_duration * (1 + extension_factor)"
          parameters:
            extension_factor:
              default: 0.2
              range: [0.1, 0.4]

      lego_state_response:
        action: "hold_position"
        rationale: "Self-correction indicates uncertainty"

    on_length_short:
      description: "Learner spoke shorter than their pattern"

      interpretation: "Could be efficiency OR giving up"

      lego_state_response:
        action: "evaluate_trend"
        rationale: "Need more context - is this new confidence or frustration?"

  # ===========================================================================
  # MASTERY STATE MACHINE (Lake-inspired, but gradient-based)
  # ===========================================================================

  mastery_states:
    description: |
      Instead of pure Fibonacci positions, we use states with fuzzy transitions.
      Inspired by Lake Waterfall but without hard resets.
      Discontinuities affect transition probabilities, not absolute moves.

    states:
      acquisition:
        description: "Initial learning - high attention needed"
        typical_skip: 1
        advancement_requires: "consecutive_smooth >= advancement_threshold"

      consolidating:
        description: "Pattern forming - moderate attention"
        typical_skip: 3
        advancement_requires: "consecutive_smooth >= advancement_threshold"

      confident:
        description: "Pattern stable - occasional reinforcement"
        typical_skip: 8
        advancement_requires: "consecutive_smooth >= advancement_threshold"

      mastered:
        description: "In eternal rotation - maintenance only"
        typical_skip: 21
        note: "Can still regress on severe discontinuity"

    transitions:
      parameters:
        advancement_threshold:
          default: 3
          range: [2, 5]
          description: "Consecutive smooth responses to advance state"

        regression_on_discontinuity:
          mild: "no change"
          moderate: "hold position"
          severe: "regress one state"

        fast_track_threshold:
          default: 5
          range: [3, 7]
          description: "Consecutive fast+smooth responses to skip a state"

    tracking_per_lego:
      consecutive_smooth: "count of responses without discontinuity"
      consecutive_fast: "count of responses faster than pattern"
      discontinuity_count: "total discontinuities for this LEGO"
      last_discontinuity_at: "timestamp of most recent discontinuity"

  # ===========================================================================
  # WEIGHTED SELECTION (Lake Waterfall inspired)
  # ===========================================================================

  weighted_selection:
    description: |
      Instead of just "due / not due", we use weighted selection.
      Every eligible LEGO has a weight. Higher weight = more likely selected.

    weight_calculation:
      formula: |
        base_weight
        * staleness_factor
        * struggle_factor
        * recency_factor

      components:
        base_weight:
          value: 1.0
          description: "Starting point for all LEGOs"

        staleness_factor:
          formula: "1 + (days_since_practice * staleness_rate)"
          parameters:
            staleness_rate:
              default: 0.1
              range: [0.05, 0.3]
              description: "Weight increase per day since last practice"

        struggle_factor:
          formula: "1 + (discontinuity_count * struggle_multiplier)"
          parameters:
            struggle_multiplier:
              default: 0.5
              range: [0.2, 1.0]
              description: "Weight boost per discontinuity"
          decay: "discontinuity_count decays over time"

        recency_factor:
          formula: "max(0.5, 1 - (minutes_since_practice / recency_window))"
          parameters:
            recency_window:
              default: 30
              range: [10, 60]
              description: "Minutes before recency penalty kicks in"
          purpose: "Slight penalty for very recent items (prevent hammering)"

    selection_algorithm:
      method: "weighted_random"
      steps:
        1: "Get eligible LEGOs (based on skip_counter >= typical_skip)"
        2: "Calculate weight for each"
        3: "Normalize weights to probabilities"
        4: "Random selection weighted by probabilities"

  # ===========================================================================
  # ROLLING STATISTICS
  # ===========================================================================

  rolling_stats:
    description: "Maintained per learner for differential calculations"

    per_learner:
      latency_history:
        type: "circular_buffer"
        max_size: 20
        fields: [timestamp, latency_ms, lego_key]

      length_delta_history:
        type: "circular_buffer"
        max_size: 20
        fields: [timestamp, length_delta_ms, lego_key]

      computed:
        rolling_avg_latency: "mean(latency_history[0:window_size])"
        rolling_stddev_latency: "stddev(latency_history[0:window_size])"
        rolling_avg_length_delta: "mean(length_delta_history[0:window_size])"
        rolling_stddev_length_delta: "stddev(length_delta_history[0:window_size])"

    cold_start:
      description: "What to do before we have enough history"

      minimum_samples:
        value: 5
        description: "Minimum responses before differential detection activates"

      behavior_before_minimum:
        discontinuity_detection: "disabled"
        selection: "round_robin within thread"
        advancement: "completion_based (not adaptive)"

  # ===========================================================================
  # LEARNER TEMPO PROFILE (Global Adaptation)
  # ===========================================================================

  learner_tempo_profile:
    description: |
      While differential detection measures deviations from a learner's OWN pattern,
      the Tempo Profile captures their OVERALL learning pace compared to typical ranges.

      This is hierarchical adaptation:
        Level 1 (Global): What kind of learner are you? → Sets baseline parameters
        Level 2 (Local):  How is this moment different? → Differential detection

      A fast processor with 1.5s average needs different app timing than a
      slow processor with 4s average. Both are valid - the app should adapt.

    philosophical_grounding: |
      Still honors "distinction as primitive" - we're measuring:
        - Inter-learner distinction: How does THIS learner differ from typical?
        - Intra-learner distinction: How does THIS moment differ from their pattern?

      Both are differential. Both are personal. Different timescales.

    assessment_phase:
      description: |
        Early in the learner's journey, we observe their natural pace
        before applying global adjustments. This happens once per learner
        (with ongoing refinement).

      parameters:
        assessment_item_count:
          default: 20
          range: [10, 50]
          description: "Items to observe before initial classification"

        assessment_complete_threshold:
          default: 15
          range: [8, 40]
          description: "Minimum valid responses needed (excluding outliers)"

      captured_metrics:
        mean_latency_ms: "Average response time across assessment"
        stddev_latency_ms: "Consistency of response times"
        mean_normalized_latency: "Latency adjusted for phrase length"
        response_variance_coefficient: "stddev / mean (consistency ratio)"

    tempo_classification:
      description: |
        Based on assessment metrics, classify learner into tempo bands.
        These bands set global parameter adjustments.

        NOTE: Thresholds are parameters - can be tuned based on population data.

      bands:
        very_fast:
          condition: "mean_normalized_latency < very_fast_threshold"
          parameters:
            very_fast_threshold:
              default: 80
              range: [50, 100]
              unit: "ms per character"
              description: "Upper bound for very_fast classification"

        fast:
          condition: "mean_normalized_latency < fast_threshold"
          parameters:
            fast_threshold:
              default: 120
              range: [80, 150]
              unit: "ms per character"

        medium:
          condition: "mean_normalized_latency < medium_threshold"
          parameters:
            medium_threshold:
              default: 180
              range: [120, 220]
              unit: "ms per character"

        slow:
          condition: "mean_normalized_latency < slow_threshold"
          parameters:
            slow_threshold:
              default: 280
              range: [180, 350]
              unit: "ms per character"

        very_slow:
          condition: "mean_normalized_latency >= slow_threshold"
          note: "Anything above slow_threshold"

    consistency_classification:
      description: |
        Independent of speed, learners vary in consistency.
        High variance learners need different handling than steady ones.

      bands:
        very_consistent:
          condition: "variance_coefficient < 0.15"
          implication: "Tight pattern - smaller stddev threshold for spikes"

        consistent:
          condition: "variance_coefficient < 0.25"
          implication: "Normal variation"

        variable:
          condition: "variance_coefficient < 0.40"
          implication: "Wide variation - larger stddev threshold needed"

        highly_variable:
          condition: "variance_coefficient >= 0.40"
          implication: "Very inconsistent - may need different detection approach"

    global_parameter_adjustments:
      description: |
        Based on tempo and consistency bands, adjust global parameters.
        These become the BASELINE that differential detection operates on.

        All adjustment factors are parameters themselves.

      by_tempo_band:
        very_fast:
          base_pause_multiplier:
            value: 0.7
            range: [0.5, 0.85]
            description: "Reduce pause duration to 70% of default"
          transition_gap_multiplier:
            value: 0.7
            range: [0.5, 0.85]
          extension_factor_adjustment:
            value: -0.1
            range: [-0.15, 0]
            description: "Reduce spike extension (they recover faster)"
          min_samples_adjustment:
            value: -1
            range: [-2, 0]
            description: "Can detect patterns earlier"

        fast:
          base_pause_multiplier:
            value: 0.85
            range: [0.7, 0.95]
          transition_gap_multiplier:
            value: 0.85
            range: [0.7, 0.95]
          extension_factor_adjustment:
            value: -0.05
            range: [-0.1, 0]
          min_samples_adjustment:
            value: 0
            range: [-1, 0]

        medium:
          base_pause_multiplier:
            value: 1.0
            description: "Default - no adjustment"
          transition_gap_multiplier:
            value: 1.0
          extension_factor_adjustment:
            value: 0
          min_samples_adjustment:
            value: 0

        slow:
          base_pause_multiplier:
            value: 1.2
            range: [1.1, 1.4]
            description: "Increase pause to 120% of default"
          transition_gap_multiplier:
            value: 1.15
            range: [1.05, 1.3]
          extension_factor_adjustment:
            value: 0.05
            range: [0, 0.15]
            description: "Slightly larger extension on spikes"
          min_samples_adjustment:
            value: 1
            range: [0, 2]
            description: "Need more data before pattern detection"

        very_slow:
          base_pause_multiplier:
            value: 1.4
            range: [1.25, 1.6]
          transition_gap_multiplier:
            value: 1.3
            range: [1.15, 1.5]
          extension_factor_adjustment:
            value: 0.1
            range: [0.05, 0.2]
          min_samples_adjustment:
            value: 2
            range: [1, 3]

      by_consistency_band:
        very_consistent:
          stddev_threshold_adjustment:
            value: -0.3
            range: [-0.5, -0.1]
            description: "Tighter spike detection - small deviations matter"

        consistent:
          stddev_threshold_adjustment:
            value: 0
            description: "Default threshold"

        variable:
          stddev_threshold_adjustment:
            value: 0.3
            range: [0.1, 0.5]
            description: "Looser spike detection - expect more variance"

        highly_variable:
          stddev_threshold_adjustment:
            value: 0.5
            range: [0.3, 0.8]
            description: "Much looser - only big deviations count"
          alternative_detection:
            note: "May benefit from percentile-based detection instead of stddev"

    profile_refinement:
      description: |
        After initial assessment, the profile continues to refine
        but at a MUCH slower rate than item-level rolling stats.

        Think: session-scale adaptation, not item-scale.

      parameters:
        refinement_window:
          default: 100
          range: [50, 200]
          unit: "items"
          description: "Items over which to calculate refined tempo"

        refinement_weight:
          default: 0.1
          range: [0.05, 0.3]
          description: "How much new data affects profile (exponential moving average)"

        max_band_shift_per_session:
          default: 1
          range: [0, 2]
          description: "Maximum tempo band shifts allowed per session"

        stability_threshold:
          default: 3
          range: [2, 5]
          unit: "sessions"
          description: "Sessions of consistent data before band shift"

      formula: |
        new_tempo_estimate = (1 - refinement_weight) * current_estimate
                          + refinement_weight * recent_window_mean

        Band shift only if:
          - new_estimate crosses threshold
          - AND has been consistent for stability_threshold sessions

    persistence:
      description: "Tempo profile is stored per learner and loaded on session start"

      stored_fields:
        - tempo_band
        - consistency_band
        - mean_normalized_latency
        - variance_coefficient
        - assessment_complete
        - last_refined_at
        - sessions_in_current_band

    integration_with_differential:
      description: |
        The tempo profile sets the STAGE. Differential detection runs the SHOW.

        Example flow:
          1. Load learner's tempo profile (slow, consistent)
          2. Apply global adjustments: pause *= 1.2, stddev_threshold -= 0.0
          3. Run session with adjusted parameters
          4. Differential detection uses adjusted baseline
          5. At session end, contribute to profile refinement

      effective_parameters:
        formula: |
          effective_pause = base_pause * tempo_pause_multiplier * spike_extension_multiplier
          effective_stddev_threshold = base_threshold + tempo_adjustment + consistency_adjustment
          effective_min_samples = base_min_samples + tempo_adjustment

  # ===========================================================================
  # VOICE ACTIVITY DETECTION (VAD) - Phase 1
  # ===========================================================================

  voice_activity_detection:
    description: |
      Real-time detection of learner vocalization during PAUSE phase.
      Uses Web Audio API to monitor microphone energy levels.
      Browser-only, no server storage - privacy by design.

    purpose:
      - "Detect whether learner is actively speaking during PAUSE"
      - "Measure engagement through activity_ratio"
      - "Provide real-time feedback for UI (is_speaking indicator)"
      - "Foundation for future prosody analysis"

    implementation:
      api: "Web Audio API (AudioContext, AnalyserNode)"
      trigger: "User gesture required for microphone access"
      lifecycle:
        1: "initialize() - Request mic access (must be from user gesture)"
        2: "startMonitoring() - Begin at PAUSE start"
        3: "stopMonitoring() - End at PAUSE end, returns VADResult"
        4: "dispose() - Clean up resources"

    parameters:
      energy_threshold_db:
        default: -45
        range: [-60, -30]
        unit: dB
        description: "RMS energy level above which we consider 'speaking'"

      min_frames_above:
        default: 3
        range: [1, 10]
        description: "Consecutive frames above threshold to confirm speech"

      fft_size:
        default: 2048
        range: [512, 4096]
        description: "FFT window size for frequency analysis"

      smoothing:
        default: 0.8
        range: [0.0, 0.95]
        description: "AnalyserNode smoothing time constant"

    output_metrics:
      speech_detected:
        type: boolean
        description: "Whether any speech was detected during PAUSE"

      speech_duration_ms:
        type: number
        description: "Total milliseconds of detected speech"

      activity_ratio:
        type: number
        range: [0, 1]
        description: "Fraction of PAUSE with detected speech (engagement signal)"

      peak_energy_db:
        type: number
        description: "Maximum energy level during monitoring"

      average_energy_db:
        type: number
        description: "Mean energy level during monitoring"

    adaptation_integration:
      description: |
        activity_ratio feeds into adaptation as an engagement signal.
        Low activity_ratio during multiple consecutive PAUSEs may indicate:
        - Disengagement
        - Confusion
        - Technical issues (mic not working)

      rolling_activity_ratio:
        window_size: 10
        description: "Rolling average of activity_ratio across items"

      response_to_low_engagement:
        threshold: 0.3
        description: "If rolling_activity_ratio < 0.3, consider engagement intervention"
        possible_actions:
          - "UI prompt to check microphone"
          - "Adjust pause duration"
          - "Simplify content selection"

  # ===========================================================================
  # PROSODY ANALYSIS - Phase 2 (Future-Proofed)
  # ===========================================================================

  prosody_analysis:
    status: "designed, not yet implemented"
    description: |
      Future capability to analyze speech characteristics:
      - Peak detection (syllable timing)
      - Gradient analysis (articulation crispness)
      - Comparison to model voice prosody

    design_philosophy: |
      Consistent with differential approach: we compare learner prosody
      to model voice prosody, not to absolute standards.
      Rolling averages smooth out noise for gradual adaptation.

    future_metrics:
      peaks:
        description: "Detected energy peaks (roughly syllables)"
        fields:
          - time_ms: "Offset from recording start"
          - amplitude: "Peak height (normalized 0-1)"
          - gradient_rise: "Rate of ascent (sharpness)"
          - gradient_fall: "Rate of descent (crispness)"
          - prominence: "Height relative to surrounding signal"

      prosody_profile:
        description: "Complete analysis of an audio segment"
        fields:
          - peaks: "Array of detected peaks"
          - rhythm_score: "Regularity of peak spacing (0-1)"
          - speech_rate: "Estimated syllables per second"
          - energy_variance: "Variation in energy levels"
          - average_gradient_sharpness: "Overall crispness indicator"

      model_comparison:
        description: "Differential between learner and model"
        fields:
          - rate_differential: "learner_rate - model_rate"
          - rhythm_similarity: "How similar the patterns are (0-1)"
          - sharpness_differential: "Crispness comparison"
          - overall_similarity: "Weighted combination (0-1)"

    adaptation_integration:
      description: |
        Prosody differentials feed into adaptation similarly to latency:
        - Large negative rate_differential = learner speaking slower
        - Low rhythm_similarity = struggling with rhythm patterns
        - Negative sharpness_differential = less crisp articulation

        These inform mastery state transitions and pause adjustments,
        but with slower adaptation (rolling averages) to avoid
        creating discontinuities in the learner's experience.

    parameters:
      min_peak_prominence:
        default: 0.1
        range: [0.05, 0.3]
        description: "Minimum prominence to detect a peak"

      min_peak_distance_ms:
        default: 80
        range: [50, 150]
        description: "Minimum milliseconds between peaks"

      gradient_window:
        default: 5
        range: [3, 10]
        description: "Samples for gradient calculation"

      sample_rate:
        default: 44100
        description: "Audio sample rate (Hz)"

  # ===========================================================================
  # PAUSE EXTENSION
  # ===========================================================================

  pause_extension:
    description: |
      When discontinuity is detected, extend pause duration for
      subsequent items to give learner more processing time.
      Extension decays over a configurable number of items.

    parameters:
      enabled:
        default: true
        description: "Whether pause extension is active"

      extension_factor:
        default: 0.3
        range: [0.1, 0.5]
        description: "Multiplier: effective_pause = base_pause * (1 + factor)"

      duration_items:
        default: 3
        range: [1, 10]
        description: "Number of items to maintain extended pause"

    behavior:
      trigger: "On discontinuity detection (spike)"
      effect: "getPauseDurationMultiplier() returns 1 + extension_factor"
      decay: "Decremented each item, resets when itemsRemaining reaches 0"
      stacking: "New trigger resets duration, doesn't stack multipliers"

  # ===========================================================================
  # PARAMETERS SUMMARY (D01: Everything is a parameter)
  # ===========================================================================

  parameters_summary:
    differential_calculation:
      - window_size: 7 [3-15]

    discontinuity_detection:
      - stddev_threshold: 2.0 [1.5-3.0]

    adaptation_responses:
      - extension_factor: 0.3 [0.1-0.5]
      - boost_factor: 2.0 [1.5-5.0]
      - consistency_threshold: 3 [2-5]

    mastery_transitions:
      - advancement_threshold: 3 [2-5]
      - fast_track_threshold: 5 [3-7]

    weighted_selection:
      - staleness_rate: 0.1 [0.05-0.3]
      - struggle_multiplier: 0.5 [0.2-1.0]
      - recency_window: 30 [10-60]

    cold_start:
      - minimum_samples: 5 [3-10]

    learner_tempo_profile:
      assessment:
        - assessment_item_count: 20 [10-50]
        - assessment_complete_threshold: 15 [8-40]
      tempo_thresholds:
        - very_fast_threshold: 80 ms/char [50-100]
        - fast_threshold: 120 ms/char [80-150]
        - medium_threshold: 180 ms/char [120-220]
        - slow_threshold: 280 ms/char [180-350]
      consistency_thresholds:
        - very_consistent: variance_coefficient < 0.15
        - consistent: variance_coefficient < 0.25
        - variable: variance_coefficient < 0.40
        - highly_variable: variance_coefficient >= 0.40
      global_adjustments_by_tempo:
        - very_fast.base_pause_multiplier: 0.7 [0.5-0.85]
        - fast.base_pause_multiplier: 0.85 [0.7-0.95]
        - medium.base_pause_multiplier: 1.0
        - slow.base_pause_multiplier: 1.2 [1.1-1.4]
        - very_slow.base_pause_multiplier: 1.4 [1.25-1.6]
      global_adjustments_by_consistency:
        - very_consistent.stddev_adjustment: -0.3 [-0.5 to -0.1]
        - consistent.stddev_adjustment: 0
        - variable.stddev_adjustment: 0.3 [0.1-0.5]
        - highly_variable.stddev_adjustment: 0.5 [0.3-0.8]
      refinement:
        - refinement_window: 100 items [50-200]
        - refinement_weight: 0.1 [0.05-0.3]
        - max_band_shift_per_session: 1 [0-2]
        - stability_threshold: 3 sessions [2-5]

    voice_activity_detection:
      - energy_threshold_db: -45 [-60 to -30]
      - min_frames_above: 3 [1-10]
      - fft_size: 2048 [512-4096]
      - smoothing: 0.8 [0.0-0.95]

    pause_extension:
      - enabled: true
      - extension_factor: 0.3 [0.1-0.5]
      - duration_items: 3 [1-10]

    prosody_analysis_future:
      - min_peak_prominence: 0.1 [0.05-0.3]
      - min_peak_distance_ms: 80 [50-150]
      - gradient_window: 5 [3-10]

  # ===========================================================================
  # UNIFIED ADAPTATION ENGINE API
  # ===========================================================================

  unified_api:
    description: |
      The AdaptationEngine class provides a unified interface that integrates
      all adaptive learning subsystems. Callers interact with one object
      that orchestrates metrics tracking, spike detection, mastery progression,
      weighted selection, and pause extension.

    primary_methods:
      processCompletion:
        signature: "processCompletion(item, latencyMs, wasFast?) → AdaptedItem + MasteryTransition"
        description: |
          Main entry point. Called after each learning cycle completes.
          Returns what action to take (continue, repeat, breakdown) and
          any mastery state transition that occurred.
        flow:
          1: "Record response metric (latency, phrase length, thread)"
          2: "Update weighted selector (mark as recently practiced)"
          3: "Process through spike detector (detect discontinuity)"
          4: "Update mastery state (smooth or discontinuity)"
          5: "If spike: record discontinuity in selector, trigger pause extension"
          6: "Return adapted item and mastery transition"

      selectFromCandidates:
        signature: "selectFromCandidates(candidates) → legoId"
        description: "Weighted random selection from eligible LEGOs"

      getTypicalSkip:
        signature: "getTypicalSkip(legoId) → number"
        description: "Returns skip value based on current mastery state"

      getPauseDurationMultiplier:
        signature: "getPauseDurationMultiplier() → number"
        description: "Returns 1.0 normally, or (1 + factor) if pause is extended"

    mastery_methods:
      getMasteryState: "Get mastery state for a specific LEGO"
      getLegosByMasteryState: "Get all LEGOs in a given state (acquisition, etc.)"
      getMasteryStats: "Aggregate stats: count by state, averages"

    selection_methods:
      getSelectionWeight: "Get calculated weight for a LEGO"
      getSelectionData: "Get staleness/discontinuity data for a LEGO"
      getCandidateWeights: "Get weights for all candidates"
      initializeLego: "Initialize tracking when LEGO is introduced"

    helper_methods:
      getLegosNeedingAttention: "LEGOs in acquisition OR with discontinuities"
      resetLegoTracking: "Reset both mastery and selection for a LEGO"

    integration_point:
      description: |
        The AdaptationEngine is designed to sit between TripleHelixEngine
        and CycleOrchestrator. The helix provides structure, the orchestrator
        plays content, and adaptation makes it personal.

  # ===========================================================================
  # INTEGRATION WITH TRIPLE HELIX
  # ===========================================================================

  integration:
    triple_helix_provides:
      - "Thread selection (A, B, C rotation)"
      - "Eligible LEGOs per thread"
      - "Interleaving structure"

    adaptation_engine_provides:
      - "Weighted selection within thread"
      - "Discontinuity detection and response"
      - "Mastery state transitions"
      - "Pause duration adjustments"

    data_flow:
      1: "TripleHelixEngine.getNextThread() → thread_id"
      2: "AdaptationEngine.getEligibleLegos(thread_id) → weighted candidates"
      3: "AdaptationEngine.selectLego(candidates) → lego"
      4: "CycleOrchestrator.play(lego) → captures latency, length"
      5: "AdaptationEngine.recordResponse(lego, latency, length)"
      6: "AdaptationEngine.detectDiscontinuity(lego)"
      7: "AdaptationEngine.applyAdaptations(lego, discontinuity)"

  # ===========================================================================
  # DESIGN DIRECTIONS ALIGNMENT
  # ===========================================================================

  design_directions:
    D01_parameterization:
      status: "strong"
      evidence: "All thresholds and factors are parameterized with ranges"

    D05_raw_over_derived:
      status: "strong"
      evidence: "Store raw latency/length, compute differentials at runtime"

    D08_explicitness:
      status: "strong"
      evidence: "Every formula and interpretation documented"

    grounded_in_distinction_primacy:
      status: "core principle"
      evidence: |
        We measure DIFFERENCES, not absolutes.
        Discontinuities are pattern breaks - distinctions that matter.
        Self-calibrating per learner - no universal thresholds.

    hierarchical_adaptation:
      status: "core principle (v1.3.0)"
      evidence: |
        Two levels of differential measurement:
        - Inter-learner: How does THIS learner differ from typical? (Tempo Profile)
        - Intra-learner: How does THIS moment differ from their pattern? (Differential)
        Both are personal. Both honor distinction primacy. Different timescales.

# =============================================================================
# VERSION HISTORY
# =============================================================================

version_history:
  v1.3.0:
    date: "2025-12-16"
    changes:
      - "Added Learner Tempo Profile - global adaptation at learner level"
      - "Two-tier hierarchical adaptation: global (tempo) + local (differential)"
      - "Assessment phase: first 20 items establish baseline tempo"
      - "Tempo bands: very_fast, fast, medium, slow, very_slow"
      - "Consistency bands: very_consistent, consistent, variable, highly_variable"
      - "Global parameter adjustments by tempo and consistency"
      - "Profile refinement: session-scale updates with stability constraints"
      - "All tempo thresholds and adjustment factors are parameters"
    design_insight: |
      Learners have different natural paces. A 1.5s average responder needs
      different app timing than a 4s average responder. Both are valid.
      The tempo profile sets the STAGE; differential detection runs the SHOW.
    implementation_status:
      learner_tempo_profile: "SPECIFIED - ready for implementation"
      mastery_state_machine: "INTEGRATED"
      weighted_selector: "INTEGRATED"
      vad: "Implemented"
      pause_extension: "INTEGRATED"
    contributors:
      - "Tom Cassidy"
      - "Claude (AI Assistant)"

  v1.2.0:
    date: "2025-12-16"
    changes:
      - "Fully integrated MasteryStateMachine into AdaptationEngine"
      - "Fully integrated WeightedSelector into AdaptationEngine"
      - "Added unified API section documenting public interface"
      - "processCompletion() now returns MasteryTransition alongside AdaptedItem"
      - "Added methods: getMasteryState, getLegosByMasteryState, getMasteryStats"
      - "Added methods: selectFromCandidates, getSelectionWeight, getCandidateWeights"
      - "Added methods: getLegosNeedingAttention, resetLegoTracking, initializeLego"
      - "Discontinuities now affect both mastery state AND selection priority"
    implementation_status:
      mastery_state_machine: "INTEGRATED - used by processCompletion()"
      weighted_selector: "INTEGRATED - used by processCompletion() and selectFromCandidates()"
      vad: "Implemented - standalone, ready for CycleOrchestrator integration"
      prosody: "Types defined, implementation deferred"
      pause_extension: "INTEGRATED - triggered by processCompletion()"
    all_tests_passing: true
    test_count: 589
    contributors:
      - "Tom Cassidy"
      - "Claude (AI Assistant)"

  v1.1.0:
    date: "2025-12-16"
    changes:
      - "Added Voice Activity Detection (VAD) - Phase 1 implementation"
      - "Added Prosody Analysis specification (Phase 2 - future-proofed)"
      - "Added Pause Extension mechanism for discontinuity response"
      - "Added VAD parameters: energy_threshold_db, min_frames_above, fft_size, smoothing"
      - "Added prosody parameters (future): peak detection, gradient analysis"
      - "Privacy by design: browser-only audio processing, no server storage"
    implementation_status:
      vad: "Implemented - VoiceActivityDetector.ts"
      prosody: "Types defined, implementation deferred"
      pause_extension: "Implemented in AdaptationEngine.ts"
    contributors:
      - "Tom Cassidy"
      - "Claude (AI Assistant)"

  v1.0.0:
    date: "2025-12-15"
    changes:
      - "Initial adaptation engine specification"
      - "Differential-based discontinuity detection"
      - "Lake Waterfall inspired weighted selection"
      - "Mastery state machine with gradient transitions"
      - "Integration with Triple Helix"
    grounded_in:
      - "APML Design Principles v2.0.0 (Distinction as Primitive)"
      - "Zenjin Maths Lake Waterfall research"
    contributors:
      - "Tom Cassidy"
      - "Claude (AI Assistant)"

# =============================================================================
# Generated: 2025-12-16
# "We don't measure absolutes. We measure DIFFERENCES."
# =============================================================================
